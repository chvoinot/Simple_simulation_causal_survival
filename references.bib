@article{gill1983large,
  title={Large sample behaviour of the product-limit estimator on the whole line},
  author={Gill, Richard},
  journal={The annals of statistics},
  pages={49--58},
  year={1983},
  publisher={JSTOR}
}

@article{royston2013restricted,
  title={Restricted mean survival time: an alternative to the hazard ratio for the design and analysis of randomized trials with a time-to-event outcome},
  author={Royston, Patrick and Parmar, Mahesh KB},
  journal={BMC medical research methodology},
  volume={13},
  pages={1--15},
  year={2013},
  publisher={Springer}
}

@article{zhang2016parametric,
  title={Parametric regression model for survival data: Weibull regression model as an example},
  author={Zhang, Zhongheng},
  journal={Annals of translational medicine},
  volume={4},
  number={24},
  year={2016},
  publisher={AME Publications}
}

@incollection{fan2010high,
  title={High-dimensional variable selection for Cox’s proportional hazards model},
  author={Fan, Jianqing and Feng, Yang and Wu, Yichao},
  booktitle={Borrowing strength: Theory powering applications--a Festschrift for Lawrence D. Brown},
  volume={6},
  pages={70--87},
  year={2010},
  publisher={Institute of Mathematical Statistics}
}

@book{kalbfleisch2002statistical,
  title={The statistical analysis of failure time data},
  author={Kalbfleisch, John D and Prentice, Ross L},
  year={2002},
  publisher={John Wiley \& Sons}
}

@article{colnet2022reweighting,
  title={Reweighting the RCT for generalization: finite sample error and variable selection},
  author={Colnet, B{\'e}n{\'e}dicte and Josse, Julie and Varoquaux, Ga{\"e}l and Scornet, Erwan},
  journal={arXiv preprint arXiv:2208.07614},
  year={2022}
}

@article{Foster_2011,
author = {Foster, Jared C. and Taylor, Jeremy M.G. and Ruberg, Stephen J.},
title = {Subgroup identification from randomized clinical trial data},
journal = {Statistics in Medicine},
volume = {30},
number = {24},
pages = {2867-2880},
keywords = {randomized clinical trials, subgroups, random forests, regression trees, tailored therapeutics},
doi = {10.1002/sim.4322},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.4322},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.4322},
abstract = {We consider the problem of identifying a subgroup of patients who may have an enhanced treatment effect in a randomized clinical trial, and it is desirable that the subgroup be defined by a limited number of covariates. For this problem, the development of a standard, pre-determined strategy may help to avoid the well-known dangers of subgroup analysis. We present a method developed to find subgroups of enhanced treatment effect. This method, referred to as ‘Virtual Twins’, involves predicting response probabilities for treatment and control ‘twins’ for each subject. The difference in these probabilities is then used as the outcome in a classification or regression tree, which can potentially include any set of the covariates. We define a measure to be the difference between the treatment effect in estimated subgroup and the marginal treatment effect. We present several methods developed to obtain an estimate of , including estimation of using estimated probabilities in the original data, using estimated probabilities in newly simulated data, two cross-validation-based approaches, and a bootstrap-based bias-corrected approach. Results of a simulation study indicate that the Virtual Twins method noticeably outperforms logistic regression with forward selection when a true subgroup of enhanced treatment effect exists. Generally, large sample sizes or strong enhanced treatment effects are needed for subgroup estimation. As an illustration, we apply the proposed methods to data from a randomized clinical trial. Copyright © 2011 John Wiley \& Sons, Ltd.},
year = {2011}
}

@article{Soren_2019,
author = {Sören R. Künzel  and Jasjeet S. Sekhon  and Peter J. Bickel  and Bin Yu },
title = {Metalearners for estimating heterogeneous treatment effects using machine learning},
journal = {Proceedings of the National Academy of Sciences},
volume = {116},
number = {10},
pages = {4156-4165},
year = {2019},
doi = {10.1073/pnas.1804597116},
URL = {https://www.pnas.org/doi/abs/10.1073/pnas.1804597116},
eprint = {https://www.pnas.org/doi/pdf/10.1073/pnas.1804597116},
abstract = {Estimating and analyzing heterogeneous treatment effects is timely, yet challenging. We introduce a unifying framework for many conditional average treatment effect estimators, and we propose a metalearner, the X-learner, which can adapt to structural properties, such as the smoothness and sparsity of the underlying treatment effect. We present its favorable properties, using theory and simulations. We apply it, using random forests, to two field experiments in political science, where it is shown to be easy to use and to produce results that are interpretable. There is growing interest in estimating and analyzing heterogeneous treatment effects in experimental and observational studies. We describe a number of metaalgorithms that can take advantage of any supervised learning or regression method in machine learning and statistics to estimate the conditional average treatment effect (CATE) function. Metaalgorithms build on base algorithms—such as random forests (RFs), Bayesian additive regression trees (BARTs), or neural networks—to estimate the CATE, a function that the base algorithms are not designed to estimate directly. We introduce a metaalgorithm, the X-learner, that is provably efficient when the number of units in one treatment group is much larger than in the other and can exploit structural properties of the CATE function. For example, if the CATE function is linear and the response functions in treatment and control are Lipschitz-continuous, the X-learner can still achieve the parametric rate under regularity conditions. We then introduce versions of the X-learner that use RF and BART as base learners. In extensive simulation studies, the X-learner performs favorably, although none of the metalearners is uniformly the best. In two persuasion field experiments from political science, we demonstrate how our X-learner can be used to target treatment regimes and to shed light on underlying mechanisms. A software package is provided that implements our methods.}}

@article{Leemis_1990,
title = {Variate generation for accelerated life and proportional hazards models with time dependent covariates},
journal = {Statistics & Probability Letters},
volume = {10},
number = {4},
pages = {335-339},
year = {1990},
issn = {0167-7152},
doi = {10.1016/0167-7152(90)90052-9},
url = {https://www.sciencedirect.com/science/article/pii/0167715290900529},
author = {Lawrence M. Leemis and Li-Hsing Shih and Kurt Reynertson},
keywords = {Accelerated life model, Monte Carlo simulation, proportional hazards model, time dependent covariates, variate generation},
abstract = {Variate generation algorithms for lifetimes when survival models incorporate time dependent covariates are presented. These algorithms are closed form for special cases of the function that links the covariate values to the survivor distribution. These algorithms are illustrated by several examples.}
}

@article{Bender_2005,
author = {Bender, Ralf and Augustin, Thomas and Blettner, Maria},
title = {Generating survival times to simulate Cox proportional hazards models},
journal = {Statistics in Medicine},
volume = {24},
number = {11},
pages = {1713-1723},
keywords = {Cox model, proportional hazards model, exponential distribution, Gompertz distribution, simulation, survival times, Weibull distribution},
doi = {10.1002/sim.2059},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2059},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.2059},
abstract = {Abstract Simulation studies present an important statistical tool to investigate the performance, properties and adequacy of statistical models in pre-specified situations. One of the most important statistical models in medical research is the proportional hazards model of Cox. In this paper, techniques to generate survival times for simulation studies regarding Cox proportional hazards models are presented. A general formula describing the relation between the hazard and the corresponding survival time of the Cox model is derived, which is useful in simulation studies. It is shown how the exponential, the Weibull and the Gompertz distribution can be applied to generate appropriate survival times for simulation studies. Additionally, the general relation between hazard and survival time can be used to develop own distributions for special situations and to handle flexibly parameterized proportional hazards models. The use of distributions other than the exponential distribution is indispensable to investigate the characteristics of the Cox proportional hazards model, especially in non-standard situations, where the partial likelihood depends on the baseline hazard. A simulation study investigating the effect of measurement errors in the German Uranium Miners Cohort Study is considered to illustrate the proposed simulation techniques and to emphasize the importance of a careful modelling of the baseline hazard in Cox models. Copyright © 2005 John Wiley \& Sons, Ltd.},
year = {2005}
}



@article{zhou1988two,
  title={Two-sided bias bound of the Kaplan-Meier estimator},
  author={Zhou, M},
  journal={Probability theory and related fields},
  volume={79},
  number={2},
  pages={165--173},
  year={1988},
  publisher={Springer}
}

@article{huitfeldt2019collapsibility,
  title = {On the collapsibility of measures of effect in the counterfactual causal framework},
  author = {Huitfeldt, A. and Stensrud, M. and Suzuki, E.},
  year = {2019},
  month = {January},
  journal = {Emerging Themes in Epidemiology},
  volume = {16},
  pages = {1--12}
}

@article{hirano2003efficient,
  title={Efficient Estimation of Average Treatment Effects Using the Estimated Propensity Score},
  author={Hirano, Keisuke and Imbens, Guido W and Ridder, Geert},
  journal={Econometrica},
  volume={71},
  number={4},
  pages={1161--1189},
  year={2003},
  publisher={Wiley Online Library}
}

@article{robins1994estimation,
  title={Estimation of Regression Coefficients When Some Regressors are not Always Observed},
  author={Robins, James M. and Rotnitzky, Andrea and Zhao, Lue Ping},
  journal={Journal of the American Statistical Association},
  volume={89},
  number={427},
  pages={846--866},
  year={1994},
  publisher={Taylor & Francis}
}

@article{greenland1999confounding,
  title = {Confounding and collapsibility in causal inference},
  author = {Greenland, S. and Robbins, J. M. and Pearl, J.},
  year = {1999},
  month = {January},
  journal = {Statistical Science},
  volume = {14},
  pages = {29--46}
}

@book{pearl2000causality,
  title = {Causality: Models, Reasoning, and Inference},
  author = {Pearl, J.},
  year = {2000},
  publisher = {Cambridge University Press}
} 

@article{ebrahimi2003identifiability,
  title={Identifiability and censored data},
  author={Ebrahimi, Nader and Molefe, Daniel and Ying, Zhiliang},
  journal={Biometrika},
  volume={90},
  number={3},
  pages={724--727},
  year={2003},
  publisher={Oxford University Press}
}

@article{ishwaran2008random,
author = {Hemant Ishwaran and Udaya B. Kogalur and Eugene H. Blackstone and Michael S. Lauer},
title = {{Random survival forests}},
volume = {2},
journal = {The Annals of Applied Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {841 -- 860},
keywords = {Conservation of events, cumulative hazard function, ensemble, out-of-bag, prediction error, survival tree},
year = {2008},
doi = {10.1214/08-AOAS169},
URL = {https://doi.org/10.1214/08-AOAS169}
}


@article{Karrison_2018,
author = {Theodore Karrison and Masha Kocherginsky},
title ={Restricted mean survival time: Does covariate adjustment improve precision in randomized clinical trials?},

journal = {Clinical Trials},
volume = {15},
number = {2},
pages = {178-188},
year = {2018},
doi = {10.1177/1740774518759281},
    note ={PMID: 29502444},

URL = { 
    
        https://doi.org/10.1177/1740774518759281
    
    

},
eprint = { 
    
        https://doi.org/10.1177/1740774518759281
    
    

}
,
    abstract = { Background:Restricted mean survival time is a measure of average survival time up to a specified time point. There has been an increased interest in using restricted mean survival time to compare treatment arms in randomized clinical trials because such comparisons do not rely on proportional hazards or other assumptions about the nature of the relationship between survival curves.Methods:This article addresses the question of whether covariate adjustment in randomized clinical trials that compare restricted mean survival times improves precision of the estimated treatment effect (difference in restricted mean survival times between treatment arms). Although precision generally increases in linear models when prognostic covariates are added, this is not necessarily the case in non-linear models. For example, in logistic and Cox regression, the standard error of the estimated treatment effect does not decrease when prognostic covariates are added, although the situation is complicated in those settings because the estimand changes as well. Because estimation of restricted mean survival time in the manner described in this article is also based on a model that is non-linear in the covariates, we investigate whether the comparison of restricted mean survival times with adjustment for covariates leads to a reduction in the standard error of the estimated treatment effect relative to the unadjusted estimator or whether covariate adjustment provides no improvement in precision. Chen and Tsiatis suggest that precision will increase if covariates are chosen judiciously. We present results of simulation studies that compare unadjusted versus adjusted comparisons of restricted mean survival time between treatment arms in randomized clinical trials.Results:We find that for comparison of restricted means in a randomized clinical trial, adjusting for covariates that are associated with survival increases precision and therefore statistical power, relative to the unadjusted estimator. Omitting important covariates results in less precision but estimates remain unbiased.Conclusion:When comparing restricted means in a randomized clinical trial, adjusting for prognostic covariates can improve precision and increase power. }
}



@article{Shen1997,
title = {Large sample properties of some survival estimators in heterogeneous samples},
journal = {Journal of Statistical Planning and Inference},
volume = {60},
number = {1},
pages = {123-138},
year = {1997},
issn = {0378-3758},
doi = {10.1016/S0378-3758(96)00124-3},
url = {https://www.sciencedirect.com/science/article/pii/S0378375896001243},
author = {Yu Shen and Thomas R. Fleming},
keywords = {62E20, 60F05, Heterogeneous samples, Kaplan-Meier estimator, Mean hazard estimator, Mean survival estimator, Proportional hazards},
abstract = {The Kaplan-Meier survival distribution estimator and Nelson hazard function estimator may not be appropriate descriptive devices for studies which involve nonhomogeneous populations. In this paper we investigate a mean survival estimator that incorporates important covariates associated with survival. The estimator is constructed based on Cox's regression model and a weighting according to any specified distribution of the baseline covariates. A mean hazard function estimator is also derived corresponding to the multiplicative intensity model which allows for recurrent outcome events. The weak convergence of each estimator is established using martingale and stochastic convergence results and its limiting variance is calculated. The strong and weak convergence of the Kaplan-Meier estimate and Nelson estimate are also explored in a nonhomogeneous population with an underlying proportional hazards model. It is shown that the Kaplan-Meier estimate remains a uniformly consistent estimate of S(t) = P(T >t) even in a heterogeneous sample if the censoring distribution is independent of covariates. However, when the censoring distribution depends on covariates, the Kaplan-Meier estimator can be quite biased even though the mean survival function estimator remains unbiased.}
}

@article{Martinussen2013,
  title     = "On collapsibility and confounding bias in Cox and Aalen
               regression models",
  author    = "Martinussen, Torben and Vansteelandt, Stijn",
  abstract  = "We study the situation where it is of interest to estimate the
               effect of an exposure variable [Formula: see text] on a survival
               time response [Formula: see text] in the presence of confounding
               by measured variables [Formula: see text]. Quantifying the
               amount of confounding is complicated by the non-collapsibility
               or non-linearity of typical effect measures in survival
               analysis: survival analyses with or without adjustment for
               [Formula: see text] typically infer different effect estimands
               of a different magnitude, even when [Formula: see text] is not
               associated with the exposure, and henceforth not a confounder of
               the association between exposure and survival time. We show
               that, interestingly, the exposure coefficient indexing the Aalen
               additive hazards model is not subject to such
               non-collapsibility, unlike the corresponding coefficient
               indexing the Cox model, so that simple measures of the amount of
               confounding bias are obtainable for the Aalen hazards model, but
               not for the Cox model. We argue that various other desirable
               properties can be ascribed to the Aalen model as a result of
               this collapsibility. This work generalizes recent work by Janes
               et al. (Biostatistics 11:572-582, 2010).",
  journal   = "Lifetime Data Anal.",
  publisher = "Springer Science and Business Media LLC",
  volume    =  19,
  number    =  3,
  pages     = "279--296",
  month     =  jul,
  year      =  2013,
  language  = "en"
}

@article{Hernan2010_HR,
  title     = "The hazards of hazard ratios",
  author    = "Hern{\'a}n, Miguel A",
  journal   = "Epidemiology",
  publisher = "Ovid Technologies (Wolters Kluwer Health)",
  volume    =  21,
  number    =  1,
  pages     = "13--15",
  month     =  jan,
  year      =  2010,
  language  = "en"
}

@book{ding2023coursecausalinference,
      title={A First Course in Causal Inference}, 
      author={Peng Ding},
      year={2023},
      eprint={2305.18793},
      archivePrefix={arXiv},
      primaryClass={stat.ME},
      url={https://arxiv.org/abs/2305.18793}, 
}

@book{Imbens_Rubin_2015, 
  place={Cambridge}, 
  title={Causal Inference for Statistics, Social, and Biomedical Sciences: An Introduction}, 
  publisher={Cambridge University Press}, 
  author={Imbens, Guido W. and Rubin, Donald B.}, 
  year={2015}} 

@article{Multiplyrobust,
    title={Multiply robust estimators of causal effects for survival outcomes},
    author={Lan Wen, Miguel A Hernan, and James M Robins},
    journal={Scand Stat Theory Appl.},
    year={2022},
    doi={10.1111/sjos.12561}
}

@book{Fan1994LocalPM,
  title={Local polynomial modelling and its applications},
  author={Jianqing Fan and Irene Gijbels},
  year={1994},
  url={https://api.semanticscholar.org/CorpusID:118744555}
}

@article{IPCtransKoul81,
author = {H. Koul and V. Susarla and J. Van Ryzin},
title = {{Regression Analysis with Randomly Right-Censored Data}},
volume = {9},
journal = {The Annals of Statistics},
number = {6},
publisher = {Institute of Mathematical Statistics},
pages = {1276 -- 1288},
keywords = {asymptotically normal, consistent, Kaplan-Meier, least squares},
year = {1981},
doi = {10.1214/aos/1176345644},
URL = {https://doi.org/10.1214/aos/1176345644}
}


@article{Cox_1972,
author = {Cox, D. R.},
title = {Regression Models and Life-Tables},
journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
volume = {34},
number = {2},
pages = {187-202},
keywords = {life table, hazard function, age-specific failure rate, product limit estimate, regression, conditional inference, asymptotic theory, censored data, two-sample rank tests, medical applications, reliability theory, accelerated life tests},
doi = {10.1111/j.2517-6161.1972.tb00899.x},
url = {https://rss.onlinelibrary.wiley.com/doi/abs/10.1111/j.2517-6161.1972.tb00899.x},
eprint = {https://rss.onlinelibrary.wiley.com/doi/pdf/10.1111/j.2517-6161.1972.tb00899.x},
abstract = {Summary The analysis of censored failure times is considered. It is assumed that on each individual are available values of one or more explanatory variables. The hazard function (age-specific failure rate) is taken to be a function of the explanatory variables and unknown regression coefficients multiplied by an arbitrary and unknown function of time. A conditional likelihood is obtained, leading to inferences about the unknown regression coefficients. Some generalizations are outlined.},
year = {1972}
}


@article{Breslow_approx1974,
 ISSN = {0006341X, 15410420},
 URL = {http://www.jstor.org/stable/2529620},
 abstract = {The use of regression models for making covariance adjustments in the comparsion of survival curves is illustrated by application to a clinical trial of maintenance therapy for childhood leukemia. Three models are considered: the log linear exponential (Glasser [1967]); Cox's [1972] nonparametric generalization of this; and the linear exponential (Feigl and Zelen [1965]). Age and white blood count at diagnosis are both shown to be important for prognosis; adjustment for the latter variable has marked effects on the treatment comparisons. Both advantages and disadvantages with the regression approach are noted.},
 author = {N. Breslow},
 journal = {Biometrics},
 number = {1},
 pages = {89--99},
 publisher = {International Biometric Society},
 title = {Covariance Analysis of Censored Survival Data},
 urldate = {2024-11-06},
 volume = {30},
 year = {1974}
}


@article{rubin_estimating_1974,
	title = {Estimating causal effects of treatments in randomized and nonrandomized studies.},
	volume = {66},
	issn = {1939-2176, 0022-0663},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/h0037350},
	doi = {10.1037/h0037350},
	language = {en},
	number = {5},
	urldate = {2023-09-26},
	journal = {Journal of Educational Psychology},
	author = {Rubin, Donald B.},
	month = oct,
	year = {1974},
	pages = {688--701},
}

@article{censoring_effect,
author = {Turkson, Anthony and Ayiah-Mensah, Francis and Nimoh, Vivian},
year = {2021},
month = {09},
pages = {1-16},
title = {Handling Censoring and Censored Data in Survival Analysis: A Standalone Systematic Literature Review},
volume = {2021},
journal = {International Journal of Mathematics and Mathematical Sciences},
doi = {10.1155/2021/9307475}
}

@article{RMST,
author = {Chen, Pei-Yun and Tsiatis, Anastasios A.},
title = {Causal Inference on the Difference of the Restricted Mean Lifetime Between Two Groups},
journal = {Biometrics},
volume = {57},
number = {4},
pages = {1030-1038},
keywords = {Causal inference, Cox's proportional hazard model, Martingale process, Observational study, Restricted lifetime, Stochastic integral, Survival analysis},
doi = {10.1111/j.0006-341X.2001.01030.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2001.01030.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.0006-341X.2001.01030.x},
abstract = {Summary. When comparing survival times between two treatment groups, it may be more appropriate to compare the restricted mean lifetime, i.e., the expectation of lifetime restricted to a time L, rather than mean lifetime in order to accommodate censoring. When the treatments are not assigned to patients randomly, as in observational studies, we also need to account for treatment imbalances in confounding factors. In this article, we propose estimators for the difference of the restricted mean lifetime between two groups that account for treatment imbalances in prognostic factors assuming a proportional hazards relationship. Large-sample properties of our estimators based on martingale theory for counting processes are also derived. Simulation studies were conducted to compare these estimators and to assess the adequacy of the large-sample approximations. Our methods are also applied to an observational database of acute coronary syndrome patients from Duke University Medical Center to estimate the treatment effect on the restricted mean lifetime over 5 years.},
year = {2001}
}

@misc{hernan2010causal,
  title={Causal inference},
  author={Hern{\'a}n, Miguel A and Robins, James M},
  year={2010},
  publisher={CRC Boca Raton, FL}
}

@article{Robins2000,
 ISSN = {10443983},
 URL = {http://www.jstor.org/stable/3703997},
 abstract = {In observational studies with exposures or treatments that vary over time, standard approaches for adjustment of confounding are biased when there exist time-dependent confounders that are also affected by previous treatment. This paper introduces marginal structural models, a new class of causal models that allow for improved adjustment of confounding in those situations. The parameters of a marginal structural model can be consistently estimated using a new class of estimators, the inverse-probability-of-treatment weighted estimators.},
 author = {James M. Robins and Miguel Ángel Hernán and Babette Brumback},
 journal = {Epidemiology},
 number = {5},
 pages = {550--560},
 publisher = {Lippincott Williams & Wilkins},
 title = {Marginal Structural Models and Causal Inference in Epidemiology},
 urldate = {2024-06-10},
 volume = {11},
 year = {2000}
}

@article{Anstrom2004,
    author = {Anstrom, Kevin J. and Tsiatis, Anastasios A.},
    title = "{Utilizing Propensity Scores to Estimate Causal Treatment Effects with Censored Time-Lagged Data}",
    journal = {Biometrics},
    volume = {57},
    number = {4},
    pages = {1207-1218},
    year = {2004},
    month = {05},
    abstract = "{Observational studies frequently are conducted to compare long-term effects of treatments. Without randomization, patients receiving one treatment are not guaranteed to be prognostically comparable to those receiving another treatment. Furthermore, the response of interest may be right-censored because of incomplete follow-up. Statistical methods that do not account for censoring and confounding may lead to biased estimates. This article presents a method for estimating treatment effects in nonrandomized studies with right-censored responses. We review the assumptions required to estimate average causal effects and derive an estimator for comparing two treatments by applying inverse weights to the complete cases. The weights are determined according to the estimated probability of receiving treatment conditional on covariates and the estimated treatment-specific censoring distribution. By utilizing martingale representations, the estimator is shown to be asymptotically normal and an estimator for the asymptotic variance is derived. Simulation results are presented to evaluate the properties of the estimator. These methods are applied to an observational data set of acute coronary syndrome patients from Duke University Medical Center to estimate the effect of a treatment strategy on the mean 5-year medical cost.}",
    issn = {0006-341X},
    doi = {10.1111/j.0006-341X.2001.01207.x},
    url = {https://doi.org/10.1111/j.0006-341X.2001.01207.x},
    eprint = {https://academic.oup.com/biometrics/article-pdf/57/4/1207/51655483/biometrics\_57\_4\_1207.pdf},
}



@article{HR_alternative,
author = {Royston, Patrick and Parmar, Mahesh},
year = {2013},
month = {12},
pages = {152},
title = {Restricted mean survival time: An alternative to the hazard ratio for the design and analysis of randomized trials with a time-to-event outcome},
volume = {13},
journal = {BMC medical research methodology},
doi = {10.1186/1471-2288-13-152}
}

@article{propensity_survival,
    author = {Anstrom, Kevin J. and Tsiatis, Anastasios A.},
    title = "{Utilizing Propensity Scores to Estimate Causal Treatment Effects with Censored Time-Lagged Data}",
    journal = {Biometrics},
    volume = {57},
    number = {4},
    pages = {1207-1218},
    year = {2004},
    month = {05},
    abstract = "{Observational studies frequently are conducted to compare long-term effects of treatments. Without randomization, patients receiving one treatment are not guaranteed to be prognostically comparable to those receiving another treatment. Furthermore, the response of interest may be right-censored because of incomplete follow-up. Statistical methods that do not account for censoring and confounding may lead to biased estimates. This article presents a method for estimating treatment effects in nonrandomized studies with right-censored responses. We review the assumptions required to estimate average causal effects and derive an estimator for comparing two treatments by applying inverse weights to the complete cases. The weights are determined according to the estimated probability of receiving treatment conditional on covariates and the estimated treatment-specific censoring distribution. By utilizing martingale representations, the estimator is shown to be asymptotically normal and an estimator for the asymptotic variance is derived. Simulation results are presented to evaluate the properties of the estimator. These methods are applied to an observational data set of acute coronary syndrome patients from Duke University Medical Center to estimate the effect of a treatment strategy on the mean 5-year medical cost.}",
    issn = {0006-341X},
    doi = {10.1111/j.0006-341X.2001.01207.x},
    url = {https://doi.org/10.1111/j.0006-341X.2001.01207.x},
    eprint = {https://academic.oup.com/biometrics/article-pdf/57/4/1207/51655483/biometrics\_57\_4\_1207.pdf},
}

@article{RMST_estimator,
	Title = {Improved precision in the analysis of randomized trials with survival outcomes, without assuming proportional hazards},
	Author = {Díaz, Iván and Colantuoni, Elizabeth and Hanley, Daniel F and Rosenblum, Michael},
	doi = {10.1007/s10985-018-9428-5},
	Number = {3},
	Volume = {25},
	Month = {July},
	Year = {2019},
	Journal = {Lifetime data analysis},
	ISSN = {1380-7870},
	Pages = {439—468},
	URL = {https://arxiv.org/pdf/1511.08404},
}



@article{kaplan,
author = {E. L. Kaplan and Paul Meier},
title = {Nonparametric Estimation from Incomplete Observations},
journal = {Journal of the American Statistical Association},
volume = {53},
number = {282},
pages = {457-481},
year = {1958},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1958.10501452},


URL = { 
    
    
        https://www.tandfonline.com/doi/abs/10.1080/01621459.1958.10501452
    

},
eprint = { 
    
    
        https://www.tandfonline.com/doi/pdf/10.1080/01621459.1958.10501452
    

}

}


@article{IPCWrobins,
author = {Robins, James M. and Finkelstein, Dianne M.},
title = {Correcting for Noncompliance and Dependent Censoring in an AIDS Clinical Trial with Inverse Probability of Censoring Weighted (IPCW) Log-Rank Tests},
journal = {Biometrics},
volume = {56},
number = {3},
pages = {779-788},
keywords = {AIDS, Causal inference, Cox proportional hazards model, Informative censoring, Survival analysis, Time-dependent covariates},
doi = {10.1111/j.0006-341X.2000.00779.x},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1111/j.0006-341X.2000.00779.x},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1111/j.0006-341X.2000.00779.x},
abstract = {Summary. AIDS Clinical Trial Group (ACTG) randomized trial 021 compared the effect of bactrim versus aerosolized pentamidine (AP) as prophylaxis therapy for pneumocystis pneumonia (POP) in AIDS patients. Although patients randomized to the bactrim arm experienced a significant delay in time to POP, the survival experience in the two arms was not significantly different (p= .32). In this paper, we present evidence that bactrim therapy improves survival but that the standard intent-to-treat comparison failed to detect this survival advantage because a large fraction of the subjects either crossed over to the other therapy or stopped therapy altogether. We obtain our evidence of a beneficial bactrim effect on survival by artificially regarding the subjects as dependently censored at the first time the subject either stops or switches therapy; we then analyze the data with the inverse probability of censoring weighted Kaplan-Meier and Cox partial likelihood estimators of Robins (1993, Proceedings of the Biopharmaceutical Section, American Statistical Association, pp. 24–33) that adjust for dependent censoring by utilizing data collected on time-dependent prognostic factors.},
year = {2000}
}

@article{Howe2016SelectionBD,
  title={Selection Bias Due to Loss to Follow Up in Cohort Studies.},
  author={Chanelle J Howe and Stephen R. Cole and Bryan Lau and Sonia Napravnik and Joseph J. Eron},
  journal={Epidemiology},
  year={2016},
  volume={27 1},
  pages={
          91-7
        },
  url={https://api.semanticscholar.org/CorpusID:21993915}
}

@Inbook{Robins1992,
author="Robins, James M.
and Rotnitzky, Andrea",
editor="Jewell, Nicholas P.
and Dietz, Klaus
and Farewell, Vernon T.",
title="Recovery of Information and Adjustment for Dependent Censoring Using Surrogate Markers",
bookTitle="AIDS Epidemiology: Methodological Issues",
year="1992",
publisher="Birkh{\"a}user Boston",
address="Boston, MA",
pages="297--331",
abstract="A class of tests and estimators for the parameters of the Cox proportional hazards model, the accelerated failure time model, and a model for the effect of treatment on the mean of a response variable of interest are proposed that use surrogate marker data to recover information lost due to independent censoring and to adjust for bias due to dependent censoring in randomized clinical trials. We construct an adaptive test that (i) is asymptotically distribution free under the null hypothesis of no treatment effect on survival, (ii) incorporates surrogate marker data, and (iii) is guaranteed to be locally more powerful than the ordinary log-rank test against proportional hazards alternatives when the baseline failure time distribution is Weibull. The proposed test is shown to outperform the log-rank test in a series of simulation experiments. We also prove the optimal estimator within our class is semiparametric efficient by first showing that our estimation problem is a special case of the general problem of parameter estimation in an arbitrary semiparametric model with data missing at random, and then deriving a representation for the efficient score in this more general problem.",
isbn="978-1-4757-1229-2",
doi="10.1007/978-1-4757-1229-2_14",
url="https://doi.org/10.1007/978-1-4757-1229-2_14"
}

@article{IPCW_consistency,
author = {Glen A Satten and Somnath Datta},
title = {The Kaplan–Meier Estimator as an Inverse-Probability-of-Censoring Weighted Average},
journal = {The American Statistician},
volume = {55},
number = {3},
pages = {207--210},
year = {2001},
publisher = {Taylor \& Francis},
doi = {10.1198/000313001317098185},

    note ={PMID: 28845048},


URL = { 
    
        https://doi.org/10.1198/000313001317098185
    
    

},
eprint = { 
    
        https://doi.org/10.1198/000313001317098185
    
    

}

}

@article{IPTW,
author = {Xie, Jun and Liu, Chaofeng},
title = {Adjusted Kaplan–Meier estimator and log-rank test with inverse probability of treatment weighting for survival data},
journal = {Statistics in Medicine},
volume = {24},
number = {20},
pages = {3089-3110},
keywords = {adjusted Kaplan–Meier estimator, IPTW, survival function, weighted log-rank test},
doi = {10.1002/sim.2174},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.2174},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.2174},
abstract = {Abstract Estimation and group comparison of survival curves are two very common issues in survival analysis. In practice, the Kaplan–Meier estimates of survival functions may be biased due to unbalanced distribution of confounders. Here we develop an adjusted Kaplan–Meier estimator (AKME) to reduce confounding effects using inverse probability of treatment weighting (IPTW). Each observation is weighted by its inverse probability of being in a certain group. The AKME is shown to be a consistent estimate of the survival function, and the variance of the AKME is derived. A weighted log-rank test is proposed for comparing group differences of survival functions. Simulation studies are used to illustrate the performance of AKME and the weighted log-rank test. The method proposed here outperforms the Kaplan–Meier estimate, and it does better than or as well as other estimators based on stratification. The AKME and the weighted log-rank test are applied to two real examples: one is the study of times to reinfection of sexually transmitted diseases, and the other is the primary biliary cirrhosis (PBC) study. Copyright © 2005 John Wiley \& Sons, Ltd.},
year = {2005}
}

@article{Nieto1996AdjustingSC,
  title={Adjusting survival curves for confounders: a review and a new method.},
  author={F. Javier Nieto and Josef Coresh},
  journal={American journal of epidemiology},
  year={1996},
  volume={143 10},
  pages={
          1059-68
        },
  url={https://api.semanticscholar.org/CorpusID:24604199}
}

@article{Propensity_causality,
    author = {Rosenbaum, Paul R. and Rubin, Donald B.},
    title = "{The central role of the propensity score in observational studies for causal effects}",
    journal = {Biometrika},
    volume = {70},
    number = {1},
    pages = {41-55},
    year = {1983},
    month = {04},
    abstract = "{The propensity score is the conditional probability of assignment to a particular treatment given a vector of observed covariates. Both large and small sample theory show that adjustment for the scalar propensity score is sufficient to remove bias due to all observed covariates. Applications include: (i) matched sampling on the univariate propensity score, which is a generalization of discriminant matching, (ii) multivariate adjustment by subclassification on the propensity score where the same subclasses are used to estimate treatment effects for all outcome variables and in all subpopulations, and (iii) visual representation of multivariate covariance adjustment by a two- dimensional plot.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/70.1.41},
    url = {https://doi.org/10.1093/biomet/70.1.41},
    eprint = {https://academic.oup.com/biomet/article-pdf/70/1/41/662954/70-1-41.pdf},
}


@article{Doubleweight,
    author = {Anstrom, Kevin J. and Tsiatis, Anastasios A.},
    title = "{Utilizing Propensity Scores to Estimate Causal Treatment Effects with Censored Time-Lagged Data}",
    journal = {Biometrics},
    volume = {57},
    number = {4},
    pages = {1207-1218},
    year = {2004},
    month = {05},
    abstract = "{Observational studies frequently are conducted to compare long-term effects of treatments. Without randomization, patients receiving one treatment are not guaranteed to be prognostically comparable to those receiving another treatment. Furthermore, the response of interest may be right-censored because of incomplete follow-up. Statistical methods that do not account for censoring and confounding may lead to biased estimates. This article presents a method for estimating treatment effects in nonrandomized studies with right-censored responses. We review the assumptions required to estimate average causal effects and derive an estimator for comparing two treatments by applying inverse weights to the complete cases. The weights are determined according to the estimated probability of receiving treatment conditional on covariates and the estimated treatment-specific censoring distribution. By utilizing martingale representations, the estimator is shown to be asymptotically normal and an estimator for the asymptotic variance is derived. Simulation results are presented to evaluate the properties of the estimator. These methods are applied to an observational data set of acute coronary syndrome patients from Duke University Medical Center to estimate the effect of a treatment strategy on the mean 5-year medical cost.}",
    issn = {0006-341X},
    doi = {10.1111/j.0006-341X.2001.01207.x},
    url = {https://doi.org/10.1111/j.0006-341X.2001.01207.x},
    eprint = {https://academic.oup.com/biometrics/article-pdf/57/4/1207/51655483/biometrics\_57\_4\_1207.pdf},
}

@article{ROBINS1986,
title = {A new approach to causal inference in mortality studies with a sustained exposure period—application to control of the healthy worker survivor effect},
journal = {Mathematical Modelling},
volume = {7},
number = {9},
pages = {1393-1512},
year = {1986},
issn = {0270-0255},
doi = {10.1016/0270-0255(86)90088-6},
url = {https://www.sciencedirect.com/science/article/pii/0270025586900886},
author = {James Robins},
abstract = {In observational cohort mortality studies with prolonged periods of exposure to the agent under study, it is not uncommon for risk factors for death to be determinants of subsequent exposure. For instance, in occupational mortality studies date of termination of employment is both a determinant of future exposure (since terminated individuals receive no further exposure) and an independent risk factor for death (since disabled individuals tend to leave employment). When current risk factor status determines subsequent exposure and is determined by previous exposure, standard analyses that estimate age-specific mortality rates as a function of cumulative exposure may underestimate the true effect of exposure on mortality whether or not one adjusts for the risk factor in the analysis. This observation raises the question, which if any population parameters can be given a causal interpretation in observational mortality studies? In answer, we offer a graphical approach to the identification and computation of causal parameters in mortality studies with sustained exposure periods. This approach is shown to be equivalent to an approach in which the observational study is identified with a hypothetical double-blind randomized trial in which data on each subject's assigned treatment protocol has been erased from the data file. Causal inferences can then be made by comparing mortality as a function of treatment protocol, since, in a double-blind randomized trial missing data on treatment protocol, the association of mortality with treatment protocol can still be estimated. We reanalyze the mortality experience of a cohort of arsenic-exposed copper smelter workers with our method and compare our results with those obtained using standard methods. We find an adverse effect of arsenic exposure on all-cause and lung cancer mortality which standard methods fail to detect.}
}

@article{Foster2011,
  title     = "Subgroup identification from randomized clinical trial data",
  author    = "Foster, Jared C and Taylor, Jeremy M G and Ruberg, Stephen J",
  journal   = "Stat. Med.",
  publisher = "Wiley",
  volume    =  30,
  number    =  24,
  pages     = "2867--2880",
  month     =  oct,
  year      =  2011,
}

@article{Kaplan_consistency,
author = {Richard Gill},
title = {{Large Sample Behaviour of the Product-Limit Estimator on the Whole Line}},
volume = {11},
journal = {The Annals of Statistics},
number = {1},
publisher = {Institute of Mathematical Statistics},
pages = {49 -- 58},
keywords = {$q$-functions, Censored data, confidence bands, counting processes, in probability linear bounds, Kaplan-Meier estimator, Martingales, mean life-time, product-limit estimator, random censorship, stochastic integrals, survival data, weak convergence},
year = {1983},
doi = {10.1214/aos/1176346055},
URL = {https://doi.org/10.1214/aos/1176346055}
}

@article{Kaplan_consistency_breslow74,
author = {N. Breslow and J. Crowley},
title = {{A Large Sample Study of the Life Table and Product Limit Estimates Under Random Censorship}},
volume = {2},
journal = {The Annals of Statistics},
number = {3},
publisher = {Institute of Mathematical Statistics},
pages = {437 -- 453},
keywords = {Censored data, consistency, Life table, Product limit, weak convergence},
year = {1974},
doi = {10.1214/aos/1176342705},
URL = {https://doi.org/10.1214/aos/1176342705}
}


@book{Aalen2008,
  title={Survival and Event History Analysis: A Process Point of View},
  author={Aalen, O. and Borgan, O. and Gjessing, H.},
  isbn={9780387685601},
  lccn={2008927364},
  series={Statistics for Biology and Health},
  url={https://books.google.de/books?id=wEi26X-VuCIC},
  year={2008},
  publisher={Springer New York}
}


@article{Susarla1980,
author = {V. Susarla and J. Van Ryzin},
title = {{Large Sample Theory for an Estimator of the Mean Survival Time from Censored Samples}},
volume = {8},
journal = {The Annals of Statistics},
number = {5},
publisher = {Institute of Mathematical Statistics},
pages = {1002 -- 1016},
keywords = {asymptotic normality, Mean survival time estimation, randomly right censored samples, strong consistency, survival analysis and $U$-statistics},
year = {1980},
doi = {10.1214/aos/1176345138},
URL = {https://doi.org/10.1214/aos/1176345138}
}

@article{IPCW,
author = {SJW Willems and A Schat and MS van Noorden and M Fiocco},
title ={Correcting for dependent censoring in routine outcome monitoring data by applying the inverse probability censoring weighted estimator},

journal = {Statistical Methods in Medical Research},
volume = {27},
number = {2},
pages = {323-335},
year = {2018},
doi = {10.1177/0962280216628900},
    note ={PMID: 26988930},

URL = { 
    
        https://doi.org/10.1177/0962280216628900
    
    

},
eprint = { 
    
        https://doi.org/10.1177/0962280216628900
    
    

}
,
    abstract = { Censored data make survival analysis more complicated because exact event times are not observed. Statistical methodology developed to account for censored observations assumes that patients’ withdrawal from a study is independent of the event of interest. However, in practice, some covariates might be associated to both lifetime and censoring mechanism, inducing dependent censoring. In this case, standard survival techniques, like Kaplan–Meier estimator, give biased results. The inverse probability censoring weighted estimator was developed to correct for bias due to dependent censoring. In this article, we explore the use of inverse probability censoring weighting methodology and describe why it is effective in removing the bias. Since implementing this method is highly time consuming and requires programming and mathematical skills, we propose a user friendly algorithm in R. Applications to a toy example and to a medical data set illustrate how the algorithm works. A simulation study was carried out to investigate the performance of the inverse probability censoring weighted estimators in situations where dependent censoring is present in the data. In the simulation process, different sample sizes, strengths of the censoring model, and percentages of censored individuals were chosen. Results show that in each scenario inverse probability censoring weighting reduces the bias induced in the traditional Kaplan–Meier approach where dependent censoring is ignored. }
}


@article{Schaubel2011,
    author = {Schaubel, Douglas E. and Wei, Guanghui},
    title = "{Double Inverse-Weighted Estimation of Cumulative Treatment Effects under Nonproportional Hazards and Dependent Censoring}",
    journal = {Biometrics},
    volume = {67},
    number = {1},
    pages = {29-38},
    year = {2011},
    month = {03},
    abstract = "{In medical studies of time-to-event data, nonproportional hazards and dependent censoring are very common issues when estimating the treatment effect. A traditional method for dealing with time-dependent treatment effects is to model the time-dependence parametrically. Limitations of this approach include the difficulty to verify the correctness of the specified functional form and the fact that, in the presence of a treatment effect that varies over time, investigators are usually interested in the cumulative as opposed to instantaneous treatment effect. In many applications, censoring time is not independent of event time. Therefore, we propose methods for estimating the cumulative treatment effect in the presence of nonproportional hazards and dependent censoring. Three measures are proposed, including the ratio of cumulative hazards, relative risk, and difference in restricted mean lifetime. For each measure, we propose a double inverse-weighted estimator, constructed by first using inverse probability of treatment weighting (IPTW) to balance the treatment-specific covariate distributions, then using inverse probability of censoring weighting (IPCW) to overcome the dependent censoring. The proposed estimators are shown to be consistent and asymptotically normal. We study their finite-sample properties through simulation. The proposed methods are used to compare kidney wait-list mortality by race.}",
    issn = {0006-341X},
    doi = {10.1111/j.1541-0420.2010.01449.x},
    url = {https://doi.org/10.1111/j.1541-0420.2010.01449.x},
    eprint = {https://academic.oup.com/biometrics/article-pdf/67/1/29/53142561/biometrics\_67\_1\_29.pdf},
}

@book{Vaart_1998, 
place={Cambridge}, 
series={Cambridge Series in Statistical and Probabilistic Mathematics}, 
title={Asymptotic Statistics}, 
publisher={Cambridge University Press}, 
author={Vaart, A. W. van der}, 
year={1998},
collection={Cambridge Series in Statistical and Probabilistic Mathematics}} 



@misc{athey2019estimating,
      title={Estimating Treatment Effects with Causal Forests: An Application}, 
      author={Susan Athey and Stefan Wager},
      year={2019},
      eprint={1902.07409},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}



@misc{wager2017estimation,
      title={Estimation and Inference of Heterogeneous Treatment Effects using Random Forests}, 
      author={Stefan Wager and Susan Athey},
      year={2017},
      eprint={1510.04342},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{1994_robinsAIPW,
author = {James M. Robins, Andrea Rotnitzky and Lue Ping Zhao},
title = {Estimation of Regression Coefficients When Some Regressors are not Always Observed},
journal = {Journal of the American Statistical Association},
volume = {89},
number = {427},
pages = {846-866},
year = {1994},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1994.10476818},


URL = { 
    
        https://doi.org/10.1080/01621459.1994.10476818
    
    

},
eprint = { 
    
        https://doi.org/10.1080/01621459.1994.10476818
    
    

}

}





@article{1995_robinsAIPW,
author = {James M. Robins, Andrea Rotnitzky and Lue Ping Zhao},
title = {Analysis of Semiparametric Regression Models for Repeated Outcomes in the Presence of Missing Data},
journal = {Journal of the American Statistical Association},
volume = {90},
number = {429},
pages = {106-121},
year = {1995},
publisher = {Taylor & Francis},
doi = {10.1080/01621459.1995.10476493},
URL = {https://www.tandfonline.com/doi/abs/10.1080/01621459.1995.10476493},
eprint = {https://www.tandfonline.com/doi/pdf/10.1080/01621459.1995.10476493}
}

@article {Hernan_HR,
	Title = {The hazards of hazard ratios},
	Author = {Hernán, Miguel A},
	DOI = {10.1097/ede.0b013e3181c1ea43},
	Number = {1},
	Volume = {21},
	Month = {January},
	Year = {2010},
	Journal = {Epidemiology (Cambridge, Mass.)},
	ISSN = {1044-3983},
	Pages = {13—15},
	URL = {https://europepmc.org/articles/PMC3653612},
}


@article{HR_Martinussen,
author = {Martinussen, Torben and Vansteelandt, Stijn and Andersen, Per},
year = {2020},
month = {10},
pages = {},
title = {Subtleties in the interpretation of hazard contrasts},
volume = {26},
journal = {Lifetime Data Analysis},
doi = {10.1007/s10985-020-09501-5}
}

@article{Buckley_james_79,
    author = {Buckley and James},
    title = "{Linear regression with censored data}",
    journal = {Biometrika},
    volume = {66},
    number = {3},
    pages = {429-436},
    year = {1979},
    month = {12},
    abstract = "{We give a method of estimating parameters in the linear regression model which allowB the dependent variable to be censored and the residual distribution to be unspecified. The method differs from that of Miller (1976) in that the normal equations rather than the sum of squares of residuals are modified and this appears to overcome the inconsistency problems in Miller's approach. Large sample properties of the estimator of slope are derived heuristically and substantiated by simulations. Some of the heart transplant data reported and analysed by Miller are reanalysed using the present method.}",
    issn = {0006-3444},
    doi = {10.1093/biomet/66.3.429},
    url = {https://doi.org/10.1093/biomet/66.3.429},
    eprint = {https://academic.oup.com/biomet/article-pdf/66/3/429/631183/66-3-429.pdf},
}

@article{DoublyR_transformation,
url = {https://doi.org/10.2202/1557-4679.1052},
title = {A Doubly Robust Censoring Unbiased Transformation},
title = {},
author = {Daniel Rubin and Mark J. van der Laan},
volume = {3},
number = {1},
journal = {The International Journal of Biostatistics},
doi = {10.2202/1557-4679.1052},
year = {2007},
lastchecked = {2024-03-29}
}

@Inbook{vanderLaan2003,
author="van der Laan, Mark J.
and Robins, James M.",
title="Introduction",
bookTitle="Unified Methods for Censored Longitudinal Data and Causality",
year="2003",
publisher="Springer New York",
address="New York, NY",
pages="8--101",
abstract="In most empirical studies, the full (equivalently, complete) data X on certain subjects are censored (equivalently, missing or coarsened). That is, the data X that one would wish to collect are incompletely observed for a (possibly improper) subset of the study subjects; instead, only a random function (equivalently, a random coarsening) Y of X is observed. Furthermore, over the past decades, data from epidemiological, biostatistical, and econometric studies have become increasingly high-dimensional as longitudinal designs that collect data on many time-varying covariate processes at frequent intervals have become commonplace. Scientific interest, however, often focuses on a low-dimensional functional $\mu$ of the distribution FXof the full data --- say, as an example, the medians of the treatment-arm specific distributions of time to tumor recurrence in a cancer clinical trial in which recurrence times are right censored by lost -to-follow-up. In such a trial, X is often high dimesional because the study protocol specifies comprehensive laboratory and clinical measurements be taken monthly. In such settings, the use of non-or semiparametric models for FXthat do not model the components of FXthat are of little scientific interest have become commonplace, so as to insure that misspecification of the functional form of a parametric model for the entire distribution FXdoes not induce biased estimates of $\mu$. The methodology described in this book was developed to meet the analytic challenges posed by high dimensional censored data in which a low-dimensional functional $\mu$ of the distribution FXis the parameter of scientific interest.",
isbn="978-0-387-21700-0",
doi="10.1007/978-0-387-21700-0_1",
url="https://doi.org/10.1007/978-0-387-21700-0_1"
}

@article{HTE_causal_survival_forests,
    author = {Cui, Yifan and Kosorok, Michael R and Sverdrup, Erik and Wager, Stefan and Zhu, Ruoqing},
    title = "{Estimating heterogeneous treatment effects with right-censored data via causal survival forests}",
    journal = {Journal of the Royal Statistical Society Series B: Statistical Methodology},
    volume = {85},
    number = {2},
    pages = {179-211},
    year = {2023},
    month = {02},
    abstract = "{Forest-based methods have recently gained in popularity for non-parametric treatment effect estimation. Building on this line of work, we introduce causal survival forests, which can be used to estimate heterogeneous treatment effects in survival and observational setting where outcomes may be right-censored. Our approach relies on orthogonal estimating equations to robustly adjust for both censoring and selection effects under unconfoundedness. In our experiments, we find our approach to perform well relative to a number of baselines.}",
    issn = {1369-7412},
    doi = {10.1093/jrsssb/qkac001},
    url = {https://doi.org/10.1093/jrsssb/qkac001},
    eprint = {https://academic.oup.com/jrsssb/article-pdf/85/2/179/50204704/qkac001.pdf},
}

@misc{DML,
Author = {Victor Chernozhukov and Denis Chetverikov and Mert Demirer and Esther Duflo and Christian Hansen and Whitney Newey and James Robins},
Title = {Double/Debiased Machine Learning for Treatment and Causal Parameters},
Year = {2016},
Eprint = {arXiv:1608.00060},}

@article{zheng2012targeted,
  title={Targeted maximum likelihood estimation of natural direct effects},
  author={Zheng, Wenjing and van der Laan, Mark J},
  journal={The international journal of biostatistics},
  volume={8},
  number={1},
  year={2012},
  publisher={NIH Public Access}
}

@article{cai2020one,
  title={One-step targeted maximum likelihood estimation for time-to-event outcomes},
  author={Cai, Weixin and van der Laan, Mark J},
  journal={Biometrics},
  volume={76},
  number={3},
  pages={722--733},
  year={2020},
  publisher={Wiley Online Library}
}

@article{grf_article,
      title={Generalized Random Forests}, 
      author={Susan Athey and Julie Tibshirani and Stefan Wager},
      year={2018},
      eprint={1610.01271},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@misc{kennedy2023semiparametric,
      title={Semiparametric doubly robust targeted double machine learning: a review}, 
      author={Edward H. Kennedy},
      year={2023},
      eprint={2203.06469},
      archivePrefix={arXiv},
      primaryClass={stat.ME}
}

@article{Stensrud2018LimitationsOH,
  title={Limitations of hazard ratios in clinical trials.},
  author={Mats Julius Stensrud and John Moene Aalen and Odd O Aalen and Morten Valberg},
  journal={European heart journal},
  year={2018},
  volume={40 17},
  pages={
          1378-1383
        },
  url={https://api.semanticscholar.org/CorpusID:54468595}
}


@article{martinussen_causality_cox,
   author = "Martinussen, Torben",
   title = "Causality and the Cox Regression Model", 
   journal= "Annual Review of Statistics and Its Application",
   year = "2022",
   volume = "9",
   number = "Volume 9, 2022",
   pages = "249-259",
   doi = "10.1146/annurev-statistics-040320-114441",
   url = "https://www.annualreviews.org/content/journals/10.1146/annurev-statistics-040320-114441",
   publisher = "Annual Reviews",
   issn = "2326-831X",
   type = "Journal Article",
   keywords = "Cox regression",
   keywords = "causality",
   keywords = "survival analysis",
   keywords = "hazard ratio",
   keywords = "randomized study",
   abstract = "This article surveys results concerning the interpretation of the Cox hazard ratio in connection to causality in a randomized study with a time-to-event response. The Cox model is assumed to be correctly specified, and we investigate whether the typical end product of such an analysis, the estimated hazard ratio, has a causal interpretation as a hazard ratio. It has been pointed out that this is not possible due to selection. We provide more insight into the interpretation of hazard ratios and differences, investigating what can be learned about a treatment effect from the hazard ratio approaching unity after a certain period of time. The conclusion is that the Cox hazard ratio is not causally interpretable as a hazard ratio unless there is no treatment effect or an untestable and unrealistic assumption holds. We give a hazard ratio that has a causal interpretation and study its relationship to the Cox hazard ratio.",
  }

@book{Hernan2020,
title={Causal Inference: What If},
author={Hernán MA, Robins JM},
year={2020},
publisher={Boca Raton: Chapman \& Hall/CRC.}

}

@book{Tsiatis2006SemiparametricTA,
  title={Semiparametric Theory and Missing Data},
  author={Anastasios A. Tsiatis},
  year={2006},
  url={https://api.semanticscholar.org/CorpusID:118005650}
}

@book{Laan2003UnifiedMF,
  title={Unified Methods for Censored Longitudinal Data and Causality},
  author={Mark J. van der Laan and James M. Robins},
  year={2003},
  url={https://api.semanticscholar.org/CorpusID:62474250}
}

@article{Aaron2021,
author = {Aaron Fisher and Edward H. Kennedy},
title = {Visually Communicating and Teaching Intuition for Influence Functions},
journal = {The American Statistician},
volume = {75},
number = {2},
pages = {162--172},
year = {2021},
publisher = {Taylor \& Francis},
doi = {10.1080/00031305.2020.1717620},


URL = { 
    
        https://doi.org/10.1080/00031305.2020.1717620
    
    

},
eprint = { 
    
        https://doi.org/10.1080/00031305.2020.1717620
    
    

}

}

@article{Hines_2022,
   title={Demystifying Statistical Learning Based on Efficient Influence Functions},
   volume={76},
   ISSN={1537-2731},
   url={http://dx.doi.org/10.1080/00031305.2021.2021984},
   DOI={10.1080/00031305.2021.2021984},
   number={3},
   journal={The American Statistician},
   publisher={Informa UK Limited},
   author={Hines, Oliver and Dukes, Oliver and Diaz-Ordaz, Karla and Vansteelandt, Stijn},
   year={2022},
   month=feb, pages={292–304} }
   


@article{Chatton_22,
author = {Arthur Chatton and Florent Le Borgne and Clémence Leyrat and Yohann Foucher},
title ={G-computation and doubly robust standardisation for continuous-time data: A comparison with inverse probability weighting},

journal = {Statistical Methods in Medical Research},
volume = {31},
number = {4},
pages = {706-718},
year = {2022},
doi = {10.1177/09622802211047345},
    note ={PMID: 34861799},

URL = { 
    
        https://doi.org/10.1177/09622802211047345
    
    

},
eprint = { 
    
        https://doi.org/10.1177/09622802211047345
    
    

}
,
    abstract = { In time-to-event settings, g-computation and doubly robust estimators are based on discrete-time data. However, many biological processes are evolving continuously over time. In this paper, we extend the g-computation and the doubly robust standardisation procedures to a continuous-time context. We compare their performance to the well-known inverse-probability-weighting estimator for the estimation of the hazard ratio and restricted mean survival times difference, using a simulation study. Under a correct model specification, all methods are unbiased, but g-computation and the doubly robust standardisation are more efficient than inverse-probability-weighting. We also analyse two real-world datasets to illustrate the practical implementation of these approaches. We have updated the R package RISCA to facilitate the use of these methods and their dissemination. }
}

@article{Ozenne20_AIPTW_AIPCW,
author = {Ozenne, Brice Maxime Hugues and Scheike, Thomas Harder and Stærk, Laila and Gerds, Thomas Alexander},
title = {On the estimation of average treatment effects with right-censored time to event outcome and competing risks},
journal = {Biometrical Journal},
volume = {62},
number = {3},
pages = {751-763},
keywords = {Cox regression model, hazard ratio, probabilistic index, relative risk, survival analysis},
doi = {10.1002/bimj.201800298},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/bimj.201800298},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/bimj.201800298},
abstract = {Abstract We are interested in the estimation of average treatment effects based on right-censored data of an observational study. We focus on causal inference of differences between t-year absolute event risks in a situation with competing risks. We derive doubly robust estimation equations and implement estimators for the nuisance parameters based on working regression models for the outcome, censoring, and treatment distribution conditional on auxiliary baseline covariates. We use the functional delta method to show that these estimators are regular asymptotically linear estimators and estimate their variances based on estimates of their influence functions. In empirical studies, we assess the robustness of the estimators and the coverage of confidence intervals. The methods are further illustrated using data from a Danish registry study.},
year = {2020}
}

@article{Stute_KMbias94,
 ISSN = {03036898, 14679469},
 URL = {http://www.jstor.org/stable/4616331},
 abstract = {Let $\hat{F}_{n}$ denote the Kaplan-Meier estimator of a lifetime distribution function computed from a sample of possibly censored data. For an arbitrary function φ we derive an expansion and an explicit formula for the bias of ∫ φ $d\hat{F}_{n}$, from which sharp lower and upper bounds are readily available.},
 author = {Winfried Stute},
 journal = {Scandinavian Journal of Statistics},
 number = {4},
 pages = {475--484},
 publisher = {[Board of the Foundation of the Scandinavian Journal of Statistics, Wiley]},
 title = {The Bias of Kaplan-Meier Integrals},
 urldate = {2024-08-06},
 volume = {21},
 year = {1994}
}

@article{LocalLinear_Fan94,
author = {Jianqing Fan and Irène Gijbels},
title = {Censored Regression: Local Linear Approximations and their Applications},
journal = {Journal of the American Statistical Association},
volume = {89},
number = {426},
pages = {560--570},
year = {1994},
publisher = {Taylor \& Francis},
doi = {10.1080/01621459.1994.10476781},
URL = {https://doi.org/10.1080/01621459.1994.10476781},
eprint = {https://doi.org/10.1080/01621459.1994.10476781}
}

@article{PseudoIPTW_Anderson2016,
author = {Andersen, Per K. and Syriopoulou, Elisavet and Parner, Erik T.},
title = {Causal inference in survival analysis using pseudo-observations},
journal = {Statistics in Medicine},
volume = {36},
number = {17},
pages = {2669-2681},
keywords = {survival data, causal inference, pseudo-observations, right-censoring, propensity score, G-formula},
doi = {10.1002/sim.7297},
url = {https://onlinelibrary.wiley.com/doi/abs/10.1002/sim.7297},
eprint = {https://onlinelibrary.wiley.com/doi/pdf/10.1002/sim.7297},
abstract = {Causal inference for non-censored response variables, such as binary or quantitative outcomes, is often based on either (1) direct standardization (‘G-formula’) or (2) inverse probability of treatment assignment weights (‘propensity score’). To do causal inference in survival analysis, one needs to address right-censoring, and often, special techniques are required for that purpose. We will show how censoring can be dealt with ‘once and for all’ by means of so-called pseudo-observations when doing causal inference in survival analysis. The pseudo-observations can be used as a replacement of the outcomes without censoring when applying ‘standard’ causal inference methods, such as (1) or (2) earlier. We study this idea for estimating the average causal effect of a binary treatment on the survival probability, the restricted mean lifetime, and the cumulative incidence in a competing risks situation. The methods will be illustrated in a small simulation study and via a study of patients with acute myeloid leukemia who received either myeloablative or non-myeloablative conditioning before allogeneic hematopoetic cell transplantation. We will estimate the average causal effect of the conditioning regime on outcomes such as the 3-year overall survival probability and the 3-year risk of chronic graft-versus-host disease. Copyright © 2017 John Wiley \& Sons, Ltd.},
year = {2017}
}

@book{Andersen1993,
  title     = "Statistical models based on counting processes",
  author    = "Andersen, Per Kragh and Borgan, Ornulf and Gill, Richard D and
               Keiding, Niels",
  publisher = "Springer",
  series    = "Springer series in statistics",
  edition   =  1,
  year      =  1993,
  address   = "New York, NY",
  language  = "en"
}

@article{robins1993,
  title={Information recovery and bias adjustment in proportional hazards regression analysis of randomized trials using surrogate markers},
  author={Robins, James M and others},
  booktitle={Proceedings of the biopharmaceutical section, American statistical association},
  volume={24},
  number={3},
  pages={3},
  year={1993},
  organization={San Francisco CA}
}

@article{Robins2004,
    author = {Robins, James and Rotnitzky, Andrea and Bonetti, Marco},
    title = "{Discussion of the Frangakis and Rubin Article}",
    journal = {Biometrics},
    volume = {57},
    number = {2},
    pages = {343-347},
    year = {2004},
    month = {05},
    issn = {0006-341X},
    doi = {10.1111/j.0006-341X.2001.00343.x},
    url = {https://doi.org/10.1111/j.0006-341X.2001.00343.x},
    eprint = {https://academic.oup.com/biometrics/article-pdf/57/2/343/51655398/biometrics\_57\_2\_343.pdf},
}



@misc{Therneau_2001, title={survival: Survival Analysis}, url={http://dx.doi.org/10.32614/CRAN.package.survival}, DOI={10.32614/cran.package.survival}, journal={CRAN: Contributed Packages}, publisher={The R Foundation}, author={Therneau, Terry M}, year={2001}, month=jun }

@misc{Tibshirani_Athey_Sverdrup_Wager_2017, title={grf: Generalized Random Forests}, url={http://dx.doi.org/10.32614/CRAN.package.grf}, DOI={10.32614/cran.package.grf}, journal={CRAN: Contributed Packages}, publisher={The R Foundation}, author={Tibshirani, Julie and Athey, Susan and Sverdrup, Erik and Wager, Stefan}, year={2017}, month=jul }

@misc{SurvRM2_2015, title={survRM2: Comparing Restricted Mean Survival Time}, url={http://dx.doi.org/10.32614/CRAN.package.survRM2}, DOI={10.32614/cran.package.survrm2}, journal={CRAN: Contributed Packages}, publisher={The R Foundation}, author = {Hajime, Uno and Lu, Tian and Miki, Horiguchi and Angel, Cronin and Chakib, Battioui and James, Bell}, year={2015}, month=feb}

@misc{Foucher_Le_Borgne_Chatton_2019, title={RISCA: Causal Inference and Prediction in Cohort-Based Analyses}, url={http://dx.doi.org/10.32614/CRAN.package.RISCA}, DOI={10.32614/cran.package.risca}, journal={CRAN: Contributed Packages}, publisher={The R Foundation}, author={Foucher, Yohann and Le Borgne, Florent and Chatton, Arthur}, year={2019}, month=aug }

@misc{EMA_RWD,
  title = {Reflection paper on use of real-world data in non-interventional studies to generate real-world evidence}, author={European Medecines Agency, EMA},
 url={https://www.ema.europa.eu/en/reflection-paper-use-real-world-data-non-interventional-studies-generate-real-world-evidence-scientific-guideline},
  year = {2024}, month=may}